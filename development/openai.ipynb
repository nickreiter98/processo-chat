{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Germany is a country located in Central Europe. It is bordered by Denmark to the north, Poland and the Czech Republic to the east, Austria and Switzerland to the south, and France, Luxembourg, Belgium, and the Netherlands to the west. Germany has a population of approximately 83 million people and its capital and largest city is Berlin. It is known for its rich history, diverse culture, technological advancements, and strong economy. Germany is a major global economic power and is also known for its contributions to fields such as science, philosophy, music, and literature. It is a member of the European Union and the United Nations.\n",
      "Certainly! I'm here to help. What would you like me to explain?\n",
      "The previous country is not mentioned in the prompt, so I cannot provide specific information about its federal states. However, many countries around the world have a federal system where power is shared between a central government and various regional or state governments. Some examples of countries with federal states include the United States, Germany, Canada, Australia, Brazil, India, and Switzerland. Each of these countries may have different names for their federal states, such as states, provinces, territories, or cantons. The number and names of federal states within a country can vary widely depending on the specific country in question.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "while True:\n",
    "  prompt = input(\"prompt: \")\n",
    "\n",
    "  completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    #functions=[RequestDetails.openai_schema],\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "  )\n",
    "\n",
    "  print(completion.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from instructor import OpenAISchema\n",
    "from pydantic import Field\n",
    "\n",
    "class RequestType(str, Enum):\n",
    "    \"\"\"User Type\"\"\"\n",
    "    process_visualization = \"process_visualization\"\n",
    "    process_optimization = \"process_optimization\"\n",
    "    process_mining = \"process_mining\"\n",
    "\n",
    "\n",
    "class RequestDetails(OpenAISchema):\n",
    "    \"\"\"User Details\"\"\"\n",
    "    process_field: str = Field(..., description=\"the requested task belongs a prcess from this specific business branch\")\n",
    "    request_type: RequestType = Field(..., description=\"the requested task belongs to this process type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPEN AI WITH PAST CONVERSATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++\n",
      "\n",
      "I apologize, but I am an AI and do not have the ability to know or be curious about things. However, I can answer any questions you may have.\n",
      "[('', 'I apologize, but I am an AI and do not have the ability to know or be curious about things. However, I can answer any questions you may have.')]\n",
      "[{'role': 'system', 'content': 'What Would you like to know today?'}, {'role': 'user', 'content': ''}]\n",
      "+++++++++++++++ /n/n\n",
      "+++++++++++++++\n",
      "do you like califlower\n",
      "As an AI, I don't have personal preferences or tastes. However, some people enjoy eating cauliflower for its nutritional benefits and versatility in recipes. It can be roasted, steamed, mashed, or used as a low-carb alternative to rice or pizza crust.\n",
      "[('', 'I apologize, but I am an AI and do not have the ability to know or be curious about things. However, I can answer any questions you may have.'), ('do you like califlower', \"As an AI, I don't have personal preferences or tastes. However, some people enjoy eating cauliflower for its nutritional benefits and versatility in recipes. It can be roasted, steamed, mashed, or used as a low-carb alternative to rice or pizza crust.\")]\n",
      "[{'role': 'system', 'content': 'What Would you like to know today?'}, {'role': 'user', 'content': ''}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': 'I apologize, but I am an AI and do not have the ability to know or be curious about things. However, I can answer any questions you may have.'}, {'role': 'user', 'content': 'do you like califlower'}]\n",
      "+++++++++++++++ /n/n\n",
      "+++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "INSTRUCTION = \"What Would you like to know today?\"\n",
    "messages = [{\"role\": \"system\", \"content\": INSTRUCTION}]\n",
    "\n",
    "previous_question_answer = []\n",
    "\n",
    "\n",
    "while True:\n",
    "    print(\"+++++++++++++++\")\n",
    "    prompt = input(INSTRUCTION)\n",
    "    print(prompt)\n",
    "\n",
    "    for question, answer in previous_question_answer:\n",
    "        messages.append({\"role\": \"user\", \"content\": question})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        #functions=[RequestDetails.openai_schema],\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    answer = completion.choices[0].message.content\n",
    "    previous_question_answer.append((prompt, answer))\n",
    "\n",
    "    if len(previous_question_answer) > 10:\n",
    "        previous_question_answer = previous_question_answer.pop(0)\n",
    "\n",
    "    print(answer)\n",
    "\n",
    "    print(previous_question_answer)\n",
    "    print(messages)\n",
    "    print(\"+++++++++++++++ /n/n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-linux",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
